{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clusters.json\", \"r\") as f:\n",
    "    clusters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Dataset/dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import string\n",
    "def clusterfy(sentence):\n",
    "    #cleaning the sentence\n",
    "    if not isinstance(sentence, str):\n",
    "        return []\n",
    "    for p in string.punctuation:\n",
    "        sentence = sentence.replace(p, \" \")\n",
    "    sentence = sentence.replace(\"  \", \" \").lower()\n",
    "    \n",
    "    \n",
    "    tokens = word_tokenize(sentence)\n",
    "    for i,token in enumerate(tokens):\n",
    "            if token in clusters[\"clusters\"]:\n",
    "                cluster_id = clusters[\"clusters\"][token]\n",
    "                tokens[i] = clusters[\"replace\"][str(cluster_id)]\n",
    "                \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the bag of words with the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = []\n",
    "for index, row in df.iterrows():\n",
    "    new_lyrics = clusterfy(row[\"lyrics\"])\n",
    "    new_title = clusterfy(row[\"title\"])\n",
    "    bag_of_words.append(new_lyrics + new_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    min_df=10,\n",
    "    lowercase=True,\n",
    "    strip_accents=\"unicode\",\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(2,2)\n",
    ")\n",
    "vectors = vectorizer.fit_transform(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Naive Bayes\": MultinomialNB(alpha=1),\n",
    "    \"SGCD\" : SGDClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"KNeighborsClassifier\" : KNeighborsClassifier(3),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(styles.tolist())\n",
    "for train_index, test_index in sss.split(vectors, labels):\n",
    "    X_train, X_test = vectors[train_index], vectors[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    categories = np.unique(labels[test_index]).tolist()\n",
    "    \n",
    "    # instanciamos o classificador\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        print(f\"=========== {classifier_name} =========\")\n",
    "        clf = classifier\n",
    "        # colocamos os nossos dados de treino\n",
    "        clf.fit(X_train, y_train)\n",
    "        # medimos sua acur√°cia com os dados de teste\n",
    "        predictions = clf.predict(X_test)\n",
    "        print(classification_report(y_test, predictions, target_names=categories))\n",
    "        print(f\"SCORE: {clf.score(X_test, y_test)}\")\n",
    "        print('-'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python project env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
