{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enriched Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"Full_data.csv\")\n",
    "original_size = len(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\"Unnamed: 0\", \"lyrics\", \"title\", \"duration_ms\", \"data\", \"analysis_url\", \"id\", \"track_href\", \"type\", \"uri\"]\n",
    "data_set = data_set.drop(drop_columns, axis=1)\n",
    "data_set[\"style\"], data_set[\"valence\"]= data_set[\"valence\"], data_set[\"style\"]\n",
    "data_set = data_set.rename(columns={\"style\": \"valence\", \"valence\": \"style\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping invalid songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_elem = data_set.isnull().any(axis=1)\n",
    "data_set = data_set[~null_elem]\n",
    "data_set = data_set.reset_index(drop=True)\n",
    "reduced_size = len(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding author, style and title\n",
    "to_encode = [\"style\", \"author\",]\n",
    "new_col_names = [\"code_style\", \"code_author\"]\n",
    "new_col_index = [len(data_set.columns)-1, 1]\n",
    "encoders = []\n",
    "for i in range(len(to_encode)):\n",
    "    values = data_set[to_encode[i]]\n",
    "    encoder = LabelEncoder()\n",
    "    encoders.append(encoder)\n",
    "    new_col = encoder.fit_transform(values) \n",
    "    data_set.insert(new_col_index[i], new_col_names[i], new_col)\n",
    "    \n",
    "# Dropping author, style and title\n",
    "drop_columns = [\"style\", \"author\"]\n",
    "data_set = data_set.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data_set.columns\n",
    "cols_to_std = cols.drop([\"code_style\"])\n",
    "data_set[cols_to_std] = data_set[cols_to_std].apply(lambda x: (x-x.mean())/x.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set reduction =  0.286112349531877\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_author</th>\n",
       "      <th>valence</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>code_style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.545075</td>\n",
       "      <td>-1.601681</td>\n",
       "      <td>-0.302035</td>\n",
       "      <td>-0.262485</td>\n",
       "      <td>-0.076129</td>\n",
       "      <td>-0.327603</td>\n",
       "      <td>-0.355787</td>\n",
       "      <td>-0.547960</td>\n",
       "      <td>0.416045</td>\n",
       "      <td>0.705209</td>\n",
       "      <td>-0.388518</td>\n",
       "      <td>0.266144</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.710051</td>\n",
       "      <td>-1.450240</td>\n",
       "      <td>-0.650304</td>\n",
       "      <td>0.250378</td>\n",
       "      <td>-0.660477</td>\n",
       "      <td>-0.327603</td>\n",
       "      <td>0.777248</td>\n",
       "      <td>-0.580874</td>\n",
       "      <td>0.506416</td>\n",
       "      <td>0.705209</td>\n",
       "      <td>-0.624666</td>\n",
       "      <td>-0.901248</td>\n",
       "      <td>-2.238318</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170012</td>\n",
       "      <td>0.906803</td>\n",
       "      <td>0.037068</td>\n",
       "      <td>0.756987</td>\n",
       "      <td>0.129627</td>\n",
       "      <td>-0.327603</td>\n",
       "      <td>-0.072528</td>\n",
       "      <td>0.839138</td>\n",
       "      <td>0.130039</td>\n",
       "      <td>0.705209</td>\n",
       "      <td>1.000506</td>\n",
       "      <td>-1.340523</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.151464</td>\n",
       "      <td>0.114650</td>\n",
       "      <td>0.923015</td>\n",
       "      <td>1.376176</td>\n",
       "      <td>-0.014402</td>\n",
       "      <td>-0.298270</td>\n",
       "      <td>-0.355787</td>\n",
       "      <td>-0.209414</td>\n",
       "      <td>-0.303892</td>\n",
       "      <td>-1.417976</td>\n",
       "      <td>-0.398785</td>\n",
       "      <td>-0.398749</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.151464</td>\n",
       "      <td>0.638869</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>-0.969236</td>\n",
       "      <td>0.923845</td>\n",
       "      <td>-0.327603</td>\n",
       "      <td>-0.922305</td>\n",
       "      <td>3.467569</td>\n",
       "      <td>0.523329</td>\n",
       "      <td>0.705209</td>\n",
       "      <td>1.029841</td>\n",
       "      <td>1.682770</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32020</th>\n",
       "      <td>-0.525744</td>\n",
       "      <td>-0.522179</td>\n",
       "      <td>-0.975966</td>\n",
       "      <td>-1.607187</td>\n",
       "      <td>1.281861</td>\n",
       "      <td>-0.327603</td>\n",
       "      <td>-0.922305</td>\n",
       "      <td>1.055431</td>\n",
       "      <td>1.199595</td>\n",
       "      <td>0.705209</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>1.951085</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32021</th>\n",
       "      <td>-1.120132</td>\n",
       "      <td>0.436948</td>\n",
       "      <td>-1.147259</td>\n",
       "      <td>-1.275703</td>\n",
       "      <td>1.425890</td>\n",
       "      <td>-0.327603</td>\n",
       "      <td>-1.205564</td>\n",
       "      <td>-0.458621</td>\n",
       "      <td>1.331113</td>\n",
       "      <td>-1.417976</td>\n",
       "      <td>0.208454</td>\n",
       "      <td>1.920414</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32022</th>\n",
       "      <td>0.980038</td>\n",
       "      <td>-0.902723</td>\n",
       "      <td>-1.081974</td>\n",
       "      <td>0.231615</td>\n",
       "      <td>1.211904</td>\n",
       "      <td>-0.327603</td>\n",
       "      <td>-0.355787</td>\n",
       "      <td>1.873583</td>\n",
       "      <td>1.365696</td>\n",
       "      <td>-1.417976</td>\n",
       "      <td>1.161850</td>\n",
       "      <td>0.379457</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32023</th>\n",
       "      <td>1.259262</td>\n",
       "      <td>-0.793996</td>\n",
       "      <td>-1.147650</td>\n",
       "      <td>-1.169377</td>\n",
       "      <td>1.450581</td>\n",
       "      <td>-0.327595</td>\n",
       "      <td>0.777248</td>\n",
       "      <td>-0.634947</td>\n",
       "      <td>1.492165</td>\n",
       "      <td>0.705209</td>\n",
       "      <td>2.276588</td>\n",
       "      <td>1.450467</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32024</th>\n",
       "      <td>-1.390141</td>\n",
       "      <td>-0.988151</td>\n",
       "      <td>-1.140599</td>\n",
       "      <td>-0.481390</td>\n",
       "      <td>1.388854</td>\n",
       "      <td>-0.327603</td>\n",
       "      <td>-0.355787</td>\n",
       "      <td>-0.860174</td>\n",
       "      <td>1.284160</td>\n",
       "      <td>-1.417976</td>\n",
       "      <td>0.286193</td>\n",
       "      <td>0.443218</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32025 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       code_author   valence  acousticness  danceability    energy  \\\n",
       "0         0.545075 -1.601681     -0.302035     -0.262485 -0.076129   \n",
       "1        -0.710051 -1.450240     -0.650304      0.250378 -0.660477   \n",
       "2         0.170012  0.906803      0.037068      0.756987  0.129627   \n",
       "3        -1.151464  0.114650      0.923015      1.376176 -0.014402   \n",
       "4        -1.151464  0.638869      0.379227     -0.969236  0.923845   \n",
       "...            ...       ...           ...           ...       ...   \n",
       "32020    -0.525744 -0.522179     -0.975966     -1.607187  1.281861   \n",
       "32021    -1.120132  0.436948     -1.147259     -1.275703  1.425890   \n",
       "32022     0.980038 -0.902723     -1.081974      0.231615  1.211904   \n",
       "32023     1.259262 -0.793996     -1.147650     -1.169377  1.450581   \n",
       "32024    -1.390141 -0.988151     -1.140599     -0.481390  1.388854   \n",
       "\n",
       "       instrumentalness       key  liveness  loudness      mode  speechiness  \\\n",
       "0             -0.327603 -0.355787 -0.547960  0.416045  0.705209    -0.388518   \n",
       "1             -0.327603  0.777248 -0.580874  0.506416  0.705209    -0.624666   \n",
       "2             -0.327603 -0.072528  0.839138  0.130039  0.705209     1.000506   \n",
       "3             -0.298270 -0.355787 -0.209414 -0.303892 -1.417976    -0.398785   \n",
       "4             -0.327603 -0.922305  3.467569  0.523329  0.705209     1.029841   \n",
       "...                 ...       ...       ...       ...       ...          ...   \n",
       "32020         -0.327603 -0.922305  1.055431  1.199595  0.705209     0.391800   \n",
       "32021         -0.327603 -1.205564 -0.458621  1.331113 -1.417976     0.208454   \n",
       "32022         -0.327603 -0.355787  1.873583  1.365696 -1.417976     1.161850   \n",
       "32023         -0.327595  0.777248 -0.634947  1.492165  0.705209     2.276588   \n",
       "32024         -0.327603 -0.355787 -0.860174  1.284160 -1.417976     0.286193   \n",
       "\n",
       "          tempo  time_signature  code_style  \n",
       "0      0.266144        0.266299           9  \n",
       "1     -0.901248       -2.238318           9  \n",
       "2     -1.340523        0.266299           6  \n",
       "3     -0.398749        0.266299           6  \n",
       "4      1.682770        0.266299           6  \n",
       "...         ...             ...         ...  \n",
       "32020  1.951085        0.266299          15  \n",
       "32021  1.920414        0.266299          15  \n",
       "32022  0.379457        0.266299          15  \n",
       "32023  1.450467        0.266299          15  \n",
       "32024  0.443218        0.266299          15  \n",
       "\n",
       "[32025 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction = (original_size-reduced_size)/original_size\n",
    "print(\"Data set reduction = \", reduction)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = data_set.drop([\"code_style\"], axis=1)\n",
    "pca = PCA()\n",
    "comp = pca.fit(data)\n",
    "importance = comp.explained_variance_/sum(comp.explained_variance_)\n",
    "for i in importance:\n",
    "    print(\"{0:.3f}\".format(i), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_set[\"code_style\"]\n",
    "X = data_set.drop([\"code_style\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.10      0.05       271\n",
      "           1       0.00      0.00      0.00       240\n",
      "           2       0.00      0.00      0.00       172\n",
      "           3       0.00      0.00      0.00       226\n",
      "           4       0.00      0.00      0.00       255\n",
      "           5       0.00      0.00      0.00       197\n",
      "           6       0.00      0.00      0.00       245\n",
      "           7       0.00      0.00      0.00       232\n",
      "           8       0.00      0.00      0.00       197\n",
      "           9       0.00      0.00      0.00       230\n",
      "          10       0.00      0.00      0.00       228\n",
      "          11       0.02      0.00      0.01       202\n",
      "          12       0.03      0.10      0.05       274\n",
      "          13       0.00      0.00      0.00       137\n",
      "          14       0.00      0.00      0.00       229\n",
      "          15       0.05      0.95      0.09       233\n",
      "          16       0.00      0.00      0.00       147\n",
      "          17       0.05      0.00      0.01       215\n",
      "          18       0.00      0.00      0.00       243\n",
      "          19       0.00      0.00      0.00        89\n",
      "          20       0.00      0.00      0.00       218\n",
      "          21       0.05      0.76      0.10       228\n",
      "          22       0.00      0.00      0.00       181\n",
      "          23       0.00      0.00      0.00       209\n",
      "          24       0.00      0.00      0.00       114\n",
      "          25       0.00      0.00      0.00       230\n",
      "          26       0.00      0.00      0.00       219\n",
      "          27       0.00      0.00      0.00       204\n",
      "          28       0.44      0.02      0.03       243\n",
      "          29       0.00      0.00      0.00       162\n",
      "          30       0.00      0.00      0.00       209\n",
      "          31       0.11      0.01      0.02       226\n",
      "          32       0.00      0.00      0.00       257\n",
      "          33       0.00      0.00      0.00       154\n",
      "          34       0.00      0.00      0.00       206\n",
      "          35       0.00      0.00      0.00       231\n",
      "          36       0.00      0.00      0.00       214\n",
      "          37       0.00      0.00      0.00       148\n",
      "          38       0.00      0.00      0.00       214\n",
      "          39       0.00      0.00      0.00       206\n",
      "          40       0.00      0.00      0.00       239\n",
      "          41       0.00      0.00      0.00       201\n",
      "          42       0.00      0.00      0.00       154\n",
      "          43       0.00      0.00      0.00       201\n",
      "          44       0.00      0.00      0.00       223\n",
      "          45       0.00      0.00      0.00       216\n",
      "          46       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.05      9608\n",
      "   macro avg       0.02      0.04      0.01      9608\n",
      "weighted avg       0.02      0.05      0.01      9608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/.local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/tristan/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver=\"sgd\", alpha=0.001, activation=\"logistic\", hidden_layer_sizes=(16+1, 50))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    \"hidden_layer_sizes\": [(100), (25,25,25,25), (98, 11, 16)],\n",
    "    \"activation\" : [\"tanh\", \"logistic\"],\n",
    "    \"solver\" : [\"sgd\", \"adam\"],\n",
    "    \"alpha\" : [0.0001, 0.05, 0.1, 1],\n",
    "    \"learning_rate\" : [\"invscaling\", \"adaptive\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/.local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=100,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_sta...\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'logistic'],\n",
       "                         'alpha': [0.0001, 0.05, 0.1, 1],\n",
       "                         'hidden_layer_sizes': [100, (25, 25, 25, 25),\n",
       "                                                (98, 11, 16)],\n",
       "                         'learning_rate': ['invscaling', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'alpha': 0.1,\n",
       " 'hidden_layer_sizes': 100,\n",
       " 'learning_rate': 'invscaling',\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.07      0.10       271\n",
      "           1       0.13      0.06      0.08       240\n",
      "           2       0.28      0.40      0.33       172\n",
      "           3       0.36      0.43      0.39       226\n",
      "           4       0.18      0.19      0.18       255\n",
      "           5       0.18      0.16      0.17       197\n",
      "           6       0.24      0.17      0.20       245\n",
      "           7       0.32      0.26      0.29       232\n",
      "           8       0.22      0.24      0.23       197\n",
      "           9       0.17      0.10      0.12       230\n",
      "          10       0.20      0.29      0.24       228\n",
      "          11       0.34      0.46      0.39       202\n",
      "          12       0.16      0.19      0.18       274\n",
      "          13       0.52      0.69      0.59       137\n",
      "          14       0.29      0.38      0.33       229\n",
      "          15       0.32      0.49      0.39       233\n",
      "          16       0.28      0.24      0.26       147\n",
      "          17       0.12      0.10      0.11       215\n",
      "          18       0.34      0.41      0.37       243\n",
      "          19       0.00      0.00      0.00        89\n",
      "          20       0.36      0.29      0.32       218\n",
      "          21       0.19      0.28      0.23       228\n",
      "          22       0.19      0.07      0.10       181\n",
      "          23       0.23      0.31      0.26       209\n",
      "          24       0.34      0.52      0.41       114\n",
      "          25       0.15      0.07      0.10       230\n",
      "          26       0.40      0.44      0.42       219\n",
      "          27       0.18      0.12      0.15       204\n",
      "          28       0.30      0.35      0.33       243\n",
      "          29       0.19      0.18      0.19       162\n",
      "          30       0.16      0.05      0.08       209\n",
      "          31       0.27      0.28      0.27       226\n",
      "          32       0.24      0.37      0.29       257\n",
      "          33       0.29      0.36      0.32       154\n",
      "          34       0.18      0.15      0.16       206\n",
      "          35       0.10      0.02      0.03       231\n",
      "          36       0.30      0.43      0.36       214\n",
      "          37       0.38      0.45      0.41       148\n",
      "          38       0.22      0.34      0.26       214\n",
      "          39       0.38      0.51      0.43       206\n",
      "          40       0.25      0.29      0.27       239\n",
      "          41       0.11      0.06      0.08       201\n",
      "          42       0.46      0.48      0.47       154\n",
      "          43       0.12      0.07      0.09       201\n",
      "          44       0.23      0.18      0.21       223\n",
      "          45       0.34      0.42      0.38       216\n",
      "          46       0.43      0.08      0.13        39\n",
      "\n",
      "    accuracy                           0.26      9608\n",
      "   macro avg       0.25      0.27      0.25      9608\n",
      "weighted avg       0.24      0.26      0.25      9608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/.local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "new = MLPClassifier(solver=\"adam\", alpha=0.1, activation=\"tanh\", hidden_layer_sizes=(100), learning_rate=\"invscaling\")\n",
    "\n",
    "new.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
